--- 
title: "Rethomics, a framework for high-throughput behaviour analysis in R"
author: "Quentin Geissmann"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: 
  bookdown::gitbook:
    includes:
       in_header: ga-script.html
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rethomics/rethomics.github.io
description: "This is a tutorial for Rethomics, a framework to analyse high-throuput behavioural data in `R`."
---
```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```

```{r, echo=FALSE}
options("datatable.print.nrows" = 30)
```

# Introduction{-}

**Only if we share a common data structure can we use a common set of tools**

--------------------

In the last few years, there has been growing interests in *ethomics* -- that is, the analysis of large behavioural data sets.
Many software and hardware solutions have been proposed to record different behavioural variables
on several model organisms.
Although subsequent analysis and visualisation share many similarities,
each method tends to provide its own output format and, in practice, its own restricted analysis software.
This results in a lot of replicated work but also limits extension and collaboration.

![The rethomics framework unify behaviour analysis over multiple platforms](assets/framework.png) 

Rethomics attempts to unify analysis of behaviour by providing several packages:

* `behavr` tables -- a  flexible and **universal structure** to handle very large behavioural data sets
* `damr`, `scopr`, … -- to **load data** from [DAMS](http://www.trikinetics.com/), [ethoscopes](https://gilestrolab.github.io/ethoscope) and others into `behavr` tables
* `ggetho` -- based on `ggplot2`, to produce **high-quality representations**  of behavioural data
* `sleepr`, `zeitgebr`, … -- to **analyse behavioural data** (sleep analysis, circadian rhythm, …)

This document is a tutorial intended for experimenters as well as data analysts.
It provides a suite of both **conceptual explanations** and very **concrete examples**.

<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# Installation and First Steps{#intro -}

## Getting R{-}

If you have never used or heard of `R` before, 
I suggest you start by reading about [data science in `R`](http://r4ds.had.co.nz/) and [installing RStudio](https://www.rstudio.com/products/rstudio/download/#download).
Only once you have done that can we continue.

## Installing rethomics packages{-}

As of today (`r Sys.Date()`), `rethomics` packages are not on CRAN, the official `R` package archive, yet.
Therefore, we will install their developmental version.

As a prerequisite, we need to install (once for all) `devtools` and load it:

```{r, eval=FALSE}
install.packages("devtools")
library(devtools)
```

Ensure you have *no error messages*. `devtool` is a package that simplifies installation of unofficial packages (for instance hosted on github) like `rethomics` ones.
Then, we can install some of the `rethomics` packages easily.
For instance, let us install `behavr`.

```{r, eval=FALSE}
install_github("rethomics/behavr")
```

In the same way, you could install other `rethomics` packages by changing `"behavr"` for another package name. 
For instance, you could install `ggetho` with `install_github("rethomics/ggetho")`.

## List of `rethomics` packages{-}

Below is a list of all the `rethomics` packages as well as their individual PDF documentation, description and build status.


```{r kable, echo=FALSE}
packages <- c("behavr", 
              "ggetho",
              "damr",
              "scopr",
              "sleepr",
              "zeitgebr"
              )
titles <- sapply(packages, 
       function(p){
          if(!p %in% rownames(installed.packages()))
            return("Unavailable")
          packageDescription(p, fields="Title")
          }
  )

package_name <- sprintf("[%s](https://github.com/rethomics/%s)", packages, packages)
doc <- sprintf("[![PDF](assets/pdf_icon.png)](https://github.com/rethomics/%s/raw/master/%s.pdf)", packages, packages)
travis_ci <- sprintf("[![%s Travis-CI Status](https://travis-ci.org/rethomics/%s.svg?branch=master)](https://travis-ci.org/rethomics/%s)", packages,packages,packages)

coverage <- sprintf("[![%s Coverage Status](https://img.shields.io/codecov/c/github/rethomics/%s/master.svg)](https://codecov.io/github/%s/behavr?branch=master)", packages, packages, packages)

# `scopr` [![Travis-CI Build Status](https://travis-ci.org/rethomics/scopr.svg?branch=master)](https://travis-ci.org/rethomics/scopr)[![Coverage Status](https://img.shields.io/codecov/c/github/rethomics/scopr/master.svg)](https://codecov.io/github/scopr/behavr?branch=master)

library(knitr)
kable(data.frame(
              Package = package_name,
              Doc = doc, 
              Description = titles,
              Travis.CI = travis_ci,
              Coverage = coverage),
      row.names = FALSE)
``` 



<!--chapter:end:01-intro.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# The `rethomics` workflow{#workflow -}


**From hypothesis to results**

---------------------------

![The rethomics workflow](assets/workflow.png)

In rethomics, we envisage behavioural experiments as a workflow:

1. **Design** -- you plan your experiment (I can't really help you with that, but I trust you!).
2. **Record/track** -- you use your acquisition platform to record behavioural variables over time. They define the format of the results.
3. **Write individual information** -- you make a spreadsheet (CSV file) that details the experimental conditions **for each individual**. We call this a **metadata file**. It is a crucial concept in rethomics, so we will dedicate it the [next section](#metadata). You can often write your metadata as you plan your experiment, but sometimes, you want to enrich it with variables that you can only record after your experiment (e.g. lifespan).
4. **Link and Load data**  -- first, we enrich your metadata by "linking" it to the result. This allows you to load all the matching data into **a single`behavr` table** (see [section on `behavr` tables](#behavr)).
5. **Tranform & analyse & visualise** -- you take advantage of `rethomics` and `R` analysis and visualisation  tools.

<!--chapter:end:02-workflow.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# Working with metadata files{#metadata -}



**Using and understanding metadata files makes your analyses more transparent and tracktable**

---------------------------

![Schematic of a metadata file](assets/metadata.png)


## What are metadata?{-}
When performing many experiments, with multiple condidions and replicates,
it becomes challenging to keep track of each individual and to link it to its actual data.
In `rethomics`, regardless of the tool used to generate data, loading results always involves a **metadata file**.
It is, in fact, **a simple CSV file** (basically a spreadsheet) in which **each row defines one unique individual**.

As shown in the figure above, metadata is classified in two types of columns:

* **Mandatory** techincal columns --  for instance `date`, `machine_name` and others (depending on the acquisition platform). They will be used to match an animal to its data. As their name suggests, they **have to** be filled. They contain the minimum information that the computer needs to sort your data.
* **Optional** experimental columns -- in this example, `condition` and `sex`. You can use as all the columns you want to characterise your experiments.


## Make them exhaustive{-}
It is a good habit to **record as much information as possible in the metadata file** -- even if it seems redundant.
For instance, if we put animals in different incubators, we can simply add an `incubator` column.
This way, we keep all our experimental notes, as much as possible, inside one file.
Not only will this help us to "debug" if anything goes wrong in one incubator, but we will also be able to account for incubator as a covariate later on.
From a computational perspective, having these extra columns is virtually free as they will not impact memory or processing time down the line.


## Put replicates together{-}

A common mistake for users is to perform several replicates of the same experiment and to make a new metadata file each time. Instead, I strongly recommand you to **put all replicates in the same file**. If it helps,
you can add a `replicate` column so you can keep track of which replicate each animal comes from.
The whole point of high-througput analysis is that you can load all the data from all replicates and compare it (and maybe merge it). The bottom line is that, if you start form a single metadata file, your work will be more trackable, and you can always decide to analyse only one replicate at a time.
Think about this metadata file as something needed in a line of research or project more than a file needed for every experiment. 


## Linking metadata{-}

![Linking adds technical columns](assets/metadata_linking.png)

Once your metadata is ready, it can be used to as a query to **import the matching data**.
Regardless of which acquisition tool you used, the first step when importing data in `R` will be "metadata linking".
This step will automatically complete the metadata file in a way that can be used for `R` to retrieve the right amount of data from experiment files. We call it linking, since it links the manually introduced metadata with the correct data file, something that is tedious to do manually. 
In short, linking means at least:

* Adding an `id` column to the metadata. This will be a unique identifier for each indididual (it generally contains datetime, machine name an region id). This will diferenciate animals with the same conditions in the metadata. 
* Adding a column that tracks "how to find the data for each individual"( i.e. local or remote path the the data file)


## Take home message{-}
In conclusion, **metadatafiles are a canonical way to both define experimental condition and load behavioural data**.
They are both computer and human friendly. In other words, if you pass a query on to a colaborator, she/he will be able to tell very quickly what individuals underwent which treatment, where and when.

<!--chapter:end:03-metadata.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# behavr tables{#behavr -}


**A single data structure to store data and metadata**

---------------------------

![a behavr table](assets/behavr.png)

## Variables and metavariables{-}

As we have seen in the [previous section](metadata.html), metadata are crucial for proper statistical analysis of the experimental **data**. In the context of ethomics, the data are long time series of recorded **variables** such as position, orientation and number of beam crosses, for each individual.
**Variables** are different form **metavariables** in so far as the latter are made of only one value per animal.
It is easier (and less error prone) to always keep the data and metadata together.
In rethomics, in order to handle large amounts of data (together with metadata), we have designed the `behavr` package.
`behavr` tables are based on the very powerful package `data.table`, but enhanced with metadata.
A `behavr` table is, indeed, formed internally by two tables: the metadata table and the data table, both are linked by the `id` column (see figure above).

For most purposes, you can use a `behavr` table just like a `data.table`.
Therefore, do take a look at the [introduction to `data.table`](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) for further details!
**When we load any behavioural data in `rethomics`, we get a `behavr` table as a result.**
In this section, we will discuss the usual operations that you can perform on `behavr` tables.



## Operating on `behavr` tables{-}

Now that we have all our data at the same place, we want to be able to manipulate it.
In the next part of this tutorial, we will create some toy data and learn how to manipulate it.
This is where basic knowledge of [`data.table`](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) comes in handy. 
The following table is an overview of operations in `behavr` tables.
`DT` represents an `behavr` table.

```{r, echo = FALSE}

section <- c("Generalities","Pure data", "","", "Pure metadata", "", "Meta & data", "", "Summarise", "", "Advanced")
ops = c("Summarise `behavr` table",
        "**Create**/alter a variable",
        "**Remove** a variable",
        "**Select** data rows",
        "Access metadata table",
        "**Create**/alter metavariable",
        "Use **metavariable as variable**",
        "**Remove individuals** according to metavariable",
        "Compute **individual statistics**",
        "**Rejoin** metadata to data",
        "**Stitch** experiments"
        )

expr = c("`summary(DT)`",
         "`DT[, new_column := some_value]`",
        "`DT[, column_to_delete := NULL]`",
        "`DT[criteria]`",
        "`DT[meta = TRUE]`",
        "`DT[, new_meta := some_value, meta=TRUE]`",
        "`xmv(metavariable)`",
        "`DT[criteria]`",
        "`DT[, .( statistics = some_math()), by='id']`",
        "`rejoin(DT)`",
        "`stitch_on(DT, metavariable)`"
        )

expl = c(
        "How many individuals, variables, metavariables, etc? -- `summary(dt)`",
        "When are animals 'very active'? -- `dt[, very_active := activity >= 2]`",
        "Lets remove a variable we don't need? --  `dt[, very_active := NULL]`",
        "Exclude data before the first hour -- `small_dt <- dt[t > hours(1)]`",
        "Show metadata as table -- `dt[meta = TRUE]`",
        "Define a new factor that is a comibiation of 'sex x condition' -- `dt[, treatment := paste(sex, condition, sep='|'), meta=T]`",
        "Add 10s to all time, only for animals in condition `'A'` -- `dt[, t := ifelse(xmv(condition) == 'A', t + 10, t)]`",
        "Remove all males (from data, and metadata) -- `dt_females <- dt[xmv(sex) == 'females']`",
        "Compute the average activity, per animal -- `stat_dt <- dt[, .(mean_acti = mean(active)), by='id']`",
        "Merge metadata and summary statistics -- `stat_dt <- rejoin(stat_dt)`",
        "TODO -- TODO"
        )



library(knitr)
kable(data.frame(
              Section = section,
              Operation = ops,
              #Schematic = fig, 
              Expression = expr,
              Example = expl),
      row.names = FALSE)
```


## Playing with toy data{-}

The `behavr` package has a set of functions to make toy data. This provides us with a playgound to test functions and plots without having to get any real data.
In order to understand `behavr` object, lets create a toy one.
First, we make some dummy metadata (always needed to create a `behavr` table):

```{r}
library(behavr)
metadata <- data.table( id = paste("toy_experiment", 1:10, sep = "|"),
                      sex = rep(c("male", "female"), each = 5),
                      condition = c("A", "B") )
metadata
```
This metadata describes an hypothetical experiment with ten animals (`1:10`, five males and  five females).
They are exposed to two conditions (`"A"` and `"B"`).
Then, we use `toy_dam_data()` to **simulate** (instead of linking/loading) one day of DAMS-like data for these ten animals (and two conditions):

```{r}
dt <- toy_dam_data(metadata, duration = days(1))
dt
```
As you can see, when we print `dt`, our `behavr` table, we have two sections: `METADATA` and `DATA`.
The former is actually just the metadata we created whilst the latter stores the data (i.e. the variables) for **all animals**. 
The special column `id` is also known as a **key**, and is shared between both data and metadata. 
It internally allows us to map them to one another.
In other words, it is a unique id for each individual.
In this specific example, the variables `t` and  `activity` are the time and the number of beam crosses, respectively.

## Generalities{-}
A quick way to retreive general information about a `behavr` table is to use `summary`:

```{r}
summary(dt)
```
This tells us immediately how many variables, metavariables and data points, we have.

One can also print a detailed summary (i.e. one per animal):

```{r}
summary(dt, detailed = TRUE)
```
### Data{-}
Playing with variables is just like in `data.table`.
Read the [official data.table tutorial](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) for more functionalities.

For instance, we can add a **new variable**, `very_active`, that is `TRUE` if and only if
there was at least two beam crosses in a minute, for a given individual:

```{r}
dt[, very_active := activity >= 2]
```

If we decide we don't need this variable anymore, we can **remove it**:


```{r}
dt[, very_active := NULL]
```


Sometimes, we would like to **filter the data**. That is, we select rows according to one or several criteria.
Often we would like to exclude the very start of the experiment. For example, we can keep data after one hour:

```{r}
dt <- dt[ t > hours(1)]
```

Note that that using `dt <-` mean we make a new table that overwrite the old one (since it has the same name).

### Metadata{-}

In order to access the metadata, we can add `meta = TRUE` inside the `[]`:

```{r}
dt[meta = TRUE]
```

This way, we can also **create new metavariables**.
For instance, say you want to collapse `sex` and `condition` which both have two levels into one `treatment`, with four levels:

```{r}
dt[, treatment := paste(sex, condition, sep='|'), meta=T]
# just to show the result:
dt[meta = TRUE]
```

`paste()` is a function that links strings of characters with an arbitrary separator (`"|"` here).

New metavariables can also be added from a summary (see [Summarise data](#summarise-data)).
### Data & Metadata {-}

The strength of `behavr` tables is their ability to seamlessly **use metavariables as though they were variables**.
For the sake of the example, let's say you would like to alter the variable `t` (time) so that we add ten seconds, *only to individuals that have condition `'A'`*.

```
dt[, t := ifelse(xmv(condition) == 'A', t + 10, t)]
```

The key here is the use of `xmv` (eXpand MetaVariable), which maps `condition` back in the data.

We can also use this mechanism to **remove individuals according to the value of a metavariable**.
For instance, lets get rid of the males!
```{r}
dt <- dt[xmv(sex) == 'female']
summary(dt)
```
When individuals are removed, metadata is automatically updated. 
In effect, we removed males from both data and metadata. 
This operation cannot be undone, as we overwrite `dt` with a new value.
An alternative would be to save the result in a new table (e.g. `dt_females <- dt[xmv(sex) == 'female']`)
This would use some additional memory, but it is safer.

### Summarise data{-}

Thanks to `data.table` `by` operations, it is simple and efficient to **compute statistics per individual**.
For instance, we may want to compute the average activity for each animal:


```{r}
stat_dt <- dt[,
   .(mean_acti = mean(activity)),
   by='id']
stat_dt
```
You can actually compute many variables in one go this way:
```{r}
stat_dt <- dt[,
   .(mean_acti = mean(activity),
     max_acti = max(activity)
     ),
   by='id']
stat_dt
```

Then, if needed, this summary can be added back to the metadata:
```{r}
# create new metadata table by joining current meta and the summary table
new_meta <- dt[stat_dt, meta=T]
# set new metadata
setmeta(dt, new_meta)
head(dt[meta=T])
```
This way we can store per-individual aggregates and visualise or analyse them with respect to the
pre-existing metadata.


Now, in order to perform statistics, we would like to merge our summaries to the metadata. 
This way we end up with only one `data.table`
That is, we want to **rejoin** them to one another (i.e. we enrich our summaries with the metadata):

```{r}
final_dt <- rejoin(stat_dt)
final_dt
```


This table is exactly what you need for statistics and visualisation in `R`!


<!-- ### Stitching{-} -->

<!-- TODO -->



<!--chapter:end:04-behavr.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# DAM2 data, in practice {#damr -}

**A matter of metadata**

---------------------------

![A DAM experiment. Two replicates, 3 days of recording each; 10 days apart; three genotypes; two sexes, males and females](assets/dam_experiment.png)

## Aims {-}
In this practical chapter, we will use a real experiment to learn how to:

* Translate your experiment design into a metadata file
* Use this metadata file to load some data
* Set the zeitgeber reference (ZT0)
* Assess graphically the quality of the data
* Use good practices to exclude individuals from our experiments

## Prerequisites {-}

* You are familiar with the [TriKineticks DAM system](http://www.trikinetics.com/)
* Ensure you have read about the [rethomics workflow](workflow.html) and [metadata](metadata.html)
* Ensure you have [installed](intro.html#installing-rethomics-packages)
`behavr`, `damr` and `ggetho` packages:


```{r, eval=FALSE}
library(devtools)
install_github("rethomics/behavr")
install_github("rethomics/damr")
install_github("rethomics/ggetho")
```




```{r, echo=FALSE}
URL <- "https://github.com/rethomics/rethomics.github.io/raw/source/material/damr_tutorial.zip"
DATA_DIR <- paste(tempdir(), "damr_tutorial", sep="/")
dir.create(DATA_DIR)
knitr::opts_knit$set(root.dir = DATA_DIR)

dst <- paste(DATA_DIR, "damr_tutorial.zip", sep="/")
download.file(URL, dst)
unzip(dst, exdir= DATA_DIR)
```

## Background{-}

[Drosophila Activity Monitors](http://www.trikinetics.com/) (DAMs) are a wildely used tool to monitor activity of fruit flies over several days. I am assuming that, if you are reading this tutorial, you are already familiar with the system, but I will make a couple of points clear before we start something more hands-on:

* This tutorial is about single beam **DAM2** but will adapt very well to multibeam DAM5.
* We work with the raw data (the data from each monitor is in one single file, and all the monitor files are in the same folder)

## Getting the data{-}

For this tutorial, you need to [download some DAM2 data](https://github.com/rethomics/rethomics.github.io/raw/source/material/damr_tutorial.zip)
that we have made available.
This is just a zip archive containing four files.
Download and extract the files from the zip into a folder of your choice.
**Store the path in a variable**.
For instance, **adapt** something like:

```r{eval=F}
DATA_DIR <- "C:/Where/My/Zip/Has/been/extracted
```

Check that all four files live there:

```{r}
list.files(DATA_DIR, pattern= "*.txt|*.csv")
```

For this exercise, we will work with the data and metadata in the same place.
However, in practice, I recommend to:

* Have **all raw data from your acquisition platform in the same place** (possibly shared with others or a network drive)
* Have **one folder per "experiment"**. That is a folder that contains one metadata file, your R scripts, your figures regarding a set of consistent experiment.

For now, we can just [set our working directory](https://support.rstudio.com/hc/en-us/articles/200711843-Working-Directories-and-Workspaces) to `DATA_DIR`:

```{r, eval=FALSE}
setwd(DATA_DIR)
```

## From experiment design to metadata{-}

### Our toy experiment{-}


![A DAM experiment. Two replicates, 3 days of recording each; 10 days apart; three genotypes; two sexes, males and females](assets/dam_experiment.png)

In this example data, we were interested in comparing the behaviour of populations of fruit flies,
according to their sex and genotype.
We designed the experiment as shown is the figure above. In summary, we have:

* **three genotypes** (A, B and C)
* **two sexes** (male and female)
* **two replicates** (`2017-07-01 -> 2017-07-04` and `2017-07-11 -> 2017-07-14`)
* Altogether, **192 individuals**


### Metadata {-}
**It is crucial that you have read [metadata chapter](metadata.html)** to understand this part.
Our goal is to encode our whole experiment in a single file in which:

* each row is an individual
* each column is a metavariable

Luckily for you, I have already put this file together for you as `metadata.csv`!
Lets have a look at it (you can use `R`, excel or whatever you want). 
If you are using `R`, type this commands:

```{r}
library(damr)
metadata <- fread("metadata.csv")
metadata
```

Each of the 192 animals (rows) is defined by a set of mandatory columns (metavariables):

* `file` -- the data file (monitor) that it has been recorded in
* `start_datetime` -- the date and time (`YYYY-MM-DD HH:MM:SS`) of the start of the experiment. Time will be considered ZT0, see [note](damr.html#zt0)
* `stop_datetime` -- the last time point of the experiment (time is optional)
* `region_id` -- the channel ([1, 32])

For **our experiment**, we also defined custom columns:

* `sex` -- M and F for male and female, respectively
* `genotype` -- A, B or C (I just made up the names for the sake of simplicity)
* `replicate` -- so we can analyse how replicates differ from one another

Note that this format is very flexible and explicit.
For instance, if we decided to do a third replicate, we would just need to add new rows.
We could also add any condition we want as a new column (e.g. treatment, temperature, matting status and so on)

## Linking{-}

[Linking](metadata.html#linking-metadata) is the one necessary step before loading the data.
It allocates a unique identifier to each animal.

It is very simple to link metadata:

```{r}
metadata <- link_dam_metadata(metadata, result_dir = DATA_DIR)
metadata
```

As `result_dir`, we just use the directory where the data lives, which you decided when you extracted your data (`DATA_DIR`).

**Importantly, you do not need to cut the relevant parts of your DAM files** (this is an error-prone step that should be avoided). In other words, no need to use the `DAMFileScan` utility or manipulate in any way the original data.

You can keep all the data in one file per monitor. `rethomics` will use start and stop datetime to find the appropriate part directly from your metadata.

## Loading {-}

In order to work with the data the last step is to load it into a [behavr](behavr.html) structure. To do that simply use `load_dam` function (as shown below). This function will store all data in dt (or any other given name)

```{r}
dt <- load_dam(metadata)
summary(dt)
```

That is it, **all** our data is loaded in dt.

## Note on datetime {-}

### ZT0 {-}
In the circadian and sleep field, we need to align our data to a reference time of the day. Typically, when the light (would) turn on (ZT0).
In `damr`, the **time part of the start_datetime is used as a circadian reference**.
For instance, if you specify, in your metadata file `2017-01-01 09:00:00`, you imply that ZT0 is at `09:00:00`.
The time is looked-up in the DAM file, so it will be at *on same time zone settings as the computer that recorded the data*.

### Start and stop time {-}

When fetching some data, date and time are **always inclusive**.

When only the date is specified:

* start time will be at `00:00:00`
* stop time will be at `23:59:59`

For instance, `start_date = 2017-01-01` and `stop_date = 2017-01-01` retrieves all the data from the first of January 2017.




## Quality control {-}
### Detecting anomalies {-}
Immediatly after loading your data, it is a good idea to visualise it, in order to detect anomalies or at least to be sure that everything looks ok.
We can use `ggetho` for that, for example the following code will create an activity tile plot, useful to detect dead animals.

```{r, fig.width = 9, fig.height=16}
library(ggetho)
# I only show fisrt replicate
ggetho(dt[xmv(replicate) == 1 ], aes(z=activity)) +
      stat_tile_etho() +
      stat_ld_annotations()
```


Here, instead of ploting everything, I show how you can subset data according to metadata in order to display only replicate one (`dt[xmv(replicate) == 1]`). In practice, you could also plot everything.
You can do a lot more with `ggetho` (see the [visualisation chapter](ggetho.html))

What does this tile plot tell us?
Each row is an animal (and is labelled with its corresponding id).
Each column is a 30min window.
The colour intensity indicates the activity.

There are two things that we can imediatly notice:

* For most animals, the activity is rythmic and synchronised with the light phase transisitions.
* Some animals are dead or missing. For instance take a look at `channel 26` in `Monitor64.txt`.

In other chapters, we will learn how to group individuals, visualise and compute statistics.

### How to exclude animals? {-}

We suggest to exclude animals *a priori* (e.g. because they died) by recording them as dead **in the metadata**. This way data is not modified or omited and can easily be recovered if needed.
For instance, you can add a column `status` in your metadata file and put a default value such as `"OK"`.
If an animal is to be removed, you can replace `"OK"` by **a reason** (e.g. `"dead"`, `"escaped"`, ...).
Then, you can load your data without those animals `load_dam_data(metadata[status == "OK"], ...)`.
This practice has the advantage of making it **very transparent**, why some individuals where excluded.
Also, as stated before, it can easily be reversed.



## Apply functions when loading {-}

Finaly, we may want to apply a function on the data as it is loaded, in order to preprocess it, saving time. This pre-processing will annotate the data, i.e create new information (new columns) based on the original data. As an example, we can perform a sleep (bouts of immobility of 5 min or more), from our `sleepr` package (which you will have installed).

```{r}
library(sleepr)
dt <- load_dam(metadata, FUN = sleepr::sleep_dam_annotation)
dt
```

```{r, echo=FALSE, eval=FALSE}
## to save the data for next tuto
# dt <- dt[xmv(replicate) == 1]
# rm(metadata)
# rm(pl)
# save(dt, file="/home/quentin/comput/rethomics/rethomics.github.io/material/sleep_dam.RData")
# load(file="/home/quentin/comput/rethomics/rethomics.github.io/material/sleep_dam.RData")
```

As you can  see, we now have additional columns in the data.


## Next steps {-}

* [Visualise data with `ggetho`](ggetho.html)
* [Sleep analysis with `sleepr`](sleepr.html)
* [Circadian analysis with `zeitgebr`](zeitgebr.html)

<!--chapter:end:05-damr.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# Ethoscope data, in practice {#scopr -}


**Large data**

---------------------------

![Example of an ethoscope experiment. Twenty flies per ethoscope are either treated or not. Positions are randomised. Two machines are used in parallel, and two replicates are performed at another time. In total, 80 animals were present in this experiment. Four `.db` files have been recorded. Tracked animals are also subsequently scored for another phenotype (gene expression level)](assets/ethoscope_experiment.png)

## Aims {-}
In this practical chapter, we will use a real experiment to learn how to:

* Translate your experiment design into a metadata file
* Use this metadata file to load some data
* Set the circadian reference (ZT0)
* Optimise your code to save time and RAM
* Assess graphically the quality of the data


## Prerequisites {-}

* You are familiar with the [Ethoscope Platform](http://gilestrolab.github.io/ethoscope/)
* Ensure you have read about the [rethomics workflow](workflow.html) and [metadata](metadata.html)
* Ensure you have [installed](intro.html#installing-rethomics-packages)
`behavr`, `scopr` and `ggetho` packages:


```{r, eval=FALSE}
library(devtools)
install_github("rethomics/behavr")
install_github("rethomics/scopr")
install_github("rethomics/ggetho")
```

```{r, echo=FALSE}
URL <- "https://zenodo.org/record/1068324/files/ethoscope_results.zip"
DATA_DIR <- paste(tempdir(), "ethoscope_tutorial", sep="/")
dir.create(DATA_DIR)
knitr::opts_knit$set(root.dir = DATA_DIR)

dst <- paste(DATA_DIR, "ethoscope_tutorial.zip", sep="/")
download.file(URL, dst)

unzip(dst, exdir= DATA_DIR)
```


## Background {-}

[The Ethoscope Platform](http://gilestrolab.github.io/ethoscope/) is a versatile and modular behavioural system to sudy behaviour of small animals. You can read more about it in our [PLOS Biology publication](http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2003026).
Although you can do much more with them, ethoscope are primarily designed to study sleep and circadian rhythms in Drosophila. 
Therefore, this tutorial targets mainly users in this context.

Ethoscopes typically generate hundreads of megabytes per machine per week.
The platform is designed so that many devices run an parallel, and the resulting data is eventually centralised for all users. 
**Metadata tables are the best way to both keep track of your expriments and fetch the relevant data.**


## Getting the data {-}
### Extract the zipped data {-}

Since ethoscopes generate **large amount of data**, compared to DAM, we will work only with a few animals.
A zip containing data for this tutorial is available on [zenodo](https://zenodo.org/record/1068324).

Start by downloading and extracting the zip somewhere in your computer.
Then, store this location as a variable. For example, **adapt** the path here:

```r{eval=F}
DATA_DIR <- "C://Where/My/Zip/Has/been/extracted
```

Check that all the files live there:

```{r}
list.files(DATA_DIR)
```

We have:

* The metadata file that I have prepared for you
* An `ethoscope_results` directory
 
### Note on the data structure {-}
It is informative to take a look at the latter.
Files are organised as `<machine_id>/<machine_name>/<datetime>/<file>`:


```
ethoscope_results
├── 008d6ba04e534be486069c3db7b10827
│   └── ETHOSCOPE_008
│       └── 2016-07-29_14-57-35
│           └── 2016-07-29_14-57-35_008d6ba04e534be486069c3db7b10827.db
├── 009d6ba04e534be486069c3db7b10827
│   └── ETHOSCOPE_009
│       └── 2016-07-22_16-43-29
│           └── 2016-07-22_16-43-29_009d6ba04e534be486069c3db7b10827.db
└── 011d6ba04e534be486069c3db7b10827
    └── ETHOSCOPE_011
        ├── 2016-07-22_16-41-21
        │   └── 2016-07-22_16-41-21_011d6ba04e534be486069c3db7b10827.db
        └── 2016-07-29_14-59-49
            └── 2016-07-29_14-59-49_011d6ba04e534be486069c3db7b10827.db
```

Tracking data are saved in `.db` files. 
Everytime an ethoscope is started, one new `.db` file is created.
All animals presents in the same machine at the same time will have their data saved in the same `.db` file.
 
### Set your working directory {-}
For this tutorial, we will just [set our working directory](https://support.rstudio.com/hc/en-us/articles/200711843-Working-Directories-and-Workspaces) to `DATA_DIR`:

```{r, eval=FALSE}
setwd(DATA_DIR)
```



## From experiment design to metadata{-}

### Our toy experiment{-}

The data I gave you is from a real experiment, but for the sake of the tutorial, I have made up a story around it. It goes like that:

* We are interested in **the effect of a drug**, let's call it the "mystery drug", on **sleep and activity** in fruit flies
* We supect this drug acts indirectly by **inhibiting the expression of a (mystery) gene**

To address these two questions, we have delivered a **drug** (yes or no) to fruit flies, and **randomised** their position in **two ethoscopes**. 
We then acquiered individual data (e.g. position and activity) about **twice a second for several days**.
We performed **two replicates**, one week appart.
In addition, in the end of the experiment, we also collected flies and **measured the relative expression of our candidate gene**.

Ultimatly, we would like to:

* Analyse the effect of the drug on sleep
* Study the correlations between the activity (or the drug) and the level of transcript
<!-- * Account for the replication design (aka [random effect](https://en.wikipedia.org/wiki/Random_effects_model)) -->



![Our experimental design](assets/ethoscope_experiment.png)


### Metadata {-}

**It is crucial that you have read [metadata chapter](metadata.html)** to understand this part.
Our goal is to encode our whole experiment in a single file in which:

* each row is an individual
* each column is a metavariable

Luckily for you, I have already put this file together for you as `metadata.csv`!
Lets have a look at it (you can use `R`, excel or whatever you want). 
If you are using `R`, type this commands:

```{r}
library(scopr)
metadata <- fread("metadata.csv")
metadata
```

Each of the 80 animals (rows) is defined by two mandatory columns (metavariables):

* `machine_name` -- the name of the device used (e.g. `"ETHOSCOPE_001"`)
* `date` -- the date and time (`YYYY-MM-DD`) of the start of the experiment
* `region_id` -- The tube (region of interest) in which an animal was tracked ([1,20])


We defined also custom columns (i.e. metavariables). Note that you could define many, with arbitrary names:

* `treatment` -- "yes" or "no", whether the drug was administered
* `replicate` -- 1 or 2, firth or second replicate
* `expression_level` -- a continuous number [0, +Inf], how much a candidate gene is transcribed


**Importantly, you should be able to understand the experiment**, and describe each animal, **from the metadata file**.


## Linking{-}

[Linking](metadata.html#linking-metadata) is the one necessary step before loading the data.
It **allocates a unique identifier to each animal**. In addition, it finds the file needed to load its data.

###  Local data {-}

If your data is already in your computer (as it is now sice you have downloaded it manually),
you can simply link it like:

```{r}
metadata <- link_ethoscope_metadata(metadata, 
                                    result_dir = "ethoscope_results")
print(metadata)
```


### Remote Data {-}

In real life situations, when several experimenters are working in parallel,
Users should not:

* Have to download all the data from all users at all time (very inefficient)
* Download data by hand from a server (error prone and time consuming)

Instead, it will be more common that all the data is stored on an **FTP** server (i.e. a network drive).
`scopr` allows us to look up in the metadata and download, incrementally, only the files needed.
For more information about how to set up network backups check the [ethocope documentation](https://qgeissmann.gitbooks.io/ethoscope-manual/administration-and-maintenance/backing-up-data.html).

In this context, we will be using `link_ethoscope_metadata_remote`.
It works almost exactly like `link_ethoscope_metadata`, but takes a `remote_dir` argument.
`remote_dir` is generally the address to an FTP directory.

This is just an example that you will have to **adapt to your own situation**:

```{r, eval=FALSE}
REMOTE_DIR <- "ftp://my-share-drive.com/where/the-data/lives"
RESULT_DIR <- "/where/to/save/the/data" 

metadata <- link_ethoscope_metadata_remote(metadata,
                                      remote_dir =  REMOTE_DIR,
                                      result_dir = RESULT_DIR,
                                      verbose = TRUE)
```

Note that, as long as you have an internet connection, you can use this function to link your metadata.
It will not download data files everytime (unless new data is available upstream).

## Loading{-}
The core fucntion of `scopr` is `load_ethoscope()`.
It is quite flexible and we will show here just a few examples of how to use it.
**Do have a look at the documentation** (e.g. by running `?load_ethoscope`), if you want to know more.


### Raw data (default) {-}

The simplest thing one can do is to load **all tracking data**.
However, this comes with several caveats:

* A lot (gigabytes) of data will be needed
* You will probably have to process the data immediatly after in order to extract biological meaning

Here, we will just load data from animals in region 1 (metadata[region_id == 1]).
As it is could otherwise be too much data:

```{r, cache=TRUE}
metadata_subset <- metadata[region_id == 1]
dt <- load_ethoscope(metadata_subset, verbose=FALSE)
summary(dt)
```
Note that I set `verbose` to `FALSE`. This is to avoid printing progress.
You may want to set it to `TRUE` (the default), so you can check how fast data loading is happening.

It is also good practice to print your resutling behavr table (`dt` in this case):
```{r}
print(dt)
```

It shows us the metadata as well as the first few and last few lines of actual data.
In the data, there are columns such as `x` and `y` that record position, but also others that may not make immediate sense to you.
**In practice, loading raw data is rare** for long experiments, and I would recommend doing it **only for prototyping** and such.
 
### Preprocessing {-}
As dissussed before, it is inneficient and not always possible to load all raw data for hundreads of animals.
Instead, we can **preprocess data on the go**.
In the context of activity and sleep analysis, we can quantified activity in windows of 10s ([techinical details here](http://journals.plos.org/plosbiology/article/file?type=supplementary&id=info:doi/10.1371/journal.pbio.2003026.s005)).
This is implemented in the function `sleep_annotation` of our `sleepr` package.
Ensure you have installed `sleepr` as well (`devtools::install_github("rethomics/sleepr")`).

When running this function:

* The activity in each 10s of data will be scored
* The position will be kept
* Sleep will be scored according to the "five minute rule"

To apply a function to **all individual data, as they are loaded**, we can use the `FUN` argument:

```{r, cache=TRUE}
dt <- load_ethoscope(metadata,
					   FUN = sleepr::sleep_annotation, 
					   verbose=FALSE)
summary(dt)
```

Again, we have a look at the resulting table:

```{r}
print(dt)
```

We have several variables (see in the  `===DATA===` section of the output).
The important ones are:

* `t` -- the time, in s, sample eveyr 10s
* `x` -- the position in the tube (0 = left, 1=right)
* `beam_cross` -- how many times the midline was crossed within the 10s window
* `moving` -- whether any movement was detected in this time window
* `asleep` -- whether the animal is asleep during this 10s (5min rule)

Note that you can use other functions than `sleep_annotation` (this is just an example) and even define your own!

### ZT0 {-}

By default, **the time is expressed relative to the onset of the experiment**.
In other words, $t_0$ is when you click on the "start tracking" button.
In the context of sleep, we care more about time **within a day**.
Therefore, we express time relative to ZT0 (i.e the hour of the day when the L phase starts).
In our lab, it is at **09:00:00, GMT**.
In `load_ethoscope`, we translate that by using the argument `reference_hour=9.0`:

```{r,eval=FALSE}
dt <- load_ethoscope(metadata,
             reference_hour=9.0, 
					   FUN = sleepr::sleep_annotation, 
					   verbose=FALSE)
```


### Cache directory {-}

One issue with loading ethoscope data is thta it is **relativelly slow**.
For instance, according to our computer, you may take half an hour to load data from 500 animals $times$ 1 week.
In your daily life, you will often need to close `R` and open it again later to analyse things differently, or simply change simple parameters on some figures. 
You really don't want to spend too long reloading data this sort of situation.

To address this issue, `load_ethoscope` comes with a [caching](https://en.wikipedia.org/wiki/Cache_(computing)) option.
When turned on, whenever you load any data, it stores a snapshot on the disk (in a directory you pick). 
Then, the *next time* you load the data, loading happends directly from the snapshot.
This way you will load data one or two orders of magnitudes faster!

The first time, everything will take as long:

```{r, cache=TRUE}
system.time(
  dt <- load_ethoscope(metadata,
             reference_hour=9.0, 
					   FUN = sleepr::sleep_annotation, 
             cache = "ethoscope_cache", 
					   verbose=FALSE)
)
```

However, the next time, we do the same thing way faster:

```{r, cache=TRUE}
system.time(
  dt <- load_ethoscope(metadata,
             reference_hour=9.0, 
					   FUN = sleepr::sleep_annotation, 
             cache = "ethoscope_cache", 
					   verbose=FALSE)
)
```

Here, we set `cache` to `"ethoscope_cache"`.
This creates a new directory called `"ethoscope_cache"` (you can pick the name and location you want).
If you to do a bit of tidying up, you can remove it without risk (it will just take time next time you load your data). 

## Quality control {-}

One way to check everything is in order with our data is to visualise it with a **tile plot**.
For instance, here, the variable `asleep`, for each animal (rows in the plot) over time (columns):

```{r, fig.width = 9, fig.height=16}
library(ggetho)
ggetho(dt, aes(z=asleep)) +
      stat_tile_etho() +
      stat_ld_annotations()
```

This allows us to spot possible outliers/missing data/artefacts and try to understand what to do whith them.
More about tiles plots in the [visualisation chapter](ggetho.html).

## And then? {-}

Just a teaser to show you how we can already work on our biological question at this stage,

### Sleep amount vs treatment {-}

We can start to see that *treatment increases sleep*:
```{r}
library(ggetho)
ggetho(dt, aes(y=asleep, colour=treatment), time_wrap = hours(24)) +
      stat_pop_etho() +
      stat_ld_annotations()
```


### Total sleep vs expression level {-}

First we [summarise](behavr.html#summerise-data) the total proportion of time spent sleeping for each animal (i.e. by id).
```{r}
summary_dt <- dt[, .(sleep_fraction = mean(asleep)), by=id]
```

Then we rejoin this summary to metadata:
```{r}
summary_dt <- rejoin(summary_dt)
summary_dt
```


This is a standard data.table (data.frame), so we can use it for some regular `R` magic.
We can show the how **sleep fraction and expression level are decorrelated**

```{r}
ggplot(summary_dt, aes(x=expression_level,
                       y=sleep_fraction,
                       colour = treatment)) +
  geom_point() +
  geom_smooth(method="lm")
```

## Next steps {-}

* [Visualise data with `ggetho`](ggetho.html)
* [Sleep analysis with `sleepr`](sleepr.html)
* [Circadian analysis with `zeitgebr`](zeitgebr.html)

<!--chapter:end:06-scopr.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# Visualisation with ggetho{#ggetho -}

<!-- **Make the most of ggetho** -->

<!-- --------------------------- -->

<!-- <!-- ![Some sort of slide show?](assets/ethoscope.jpg) --> 
<!-- **TODO, a demo of some plots**  -->


## Aims {-}
In this practical chapter, we will generate toy data to learn how to:

* Express a question as a relationship beween variables
* Use tile plots to show individual data
* Make population plots
* Wrap data around circadian time
* Make double-plotted actograms
* Annotate plot with light and dark phases
* Use ggplot tools (facets, scales) to enhance plots
* Plot average and individual periodograms

## Prerequisites {-}

* Some familiarity with [ggplot](http://ggplot2.org/)
* Ensure you have [installed](intro.html#installing-rethomics-packages)
`behavr`and `ggetho` packages:


```{r, eval=FALSE}
library(devtools)
install_github("rethmics/behavr")
install_github("rethmics/ggetho")
```



## Lessons from ggplot{-}
In the previous tutorials, we have used `ggetho` to visualise out behavioural data.
This section will explain further how this package can be used to produce flexible plots and how it integrates with `ggplot2`.

[ggplot2](http://ggplot2.org/) is one of the most popular visualisation tool and an unavoidable `R` package.
It implements the powerful concepts of the ["Grammar of graphics"](https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/GOG.html).
The package `ggetho`, which we discuss here, extends `ggplot` for the specific case of behavioural analysis.
At this stage, you really want to have some familiarity with `ggplot2` so you understand its logic.
You will find a fair numbers of [videos](https://www.youtube.com/watch?v=TaxJwC_MP9Q) and [books](http://ggplot2.org/book/) online.


## Some behavioural data{-}

In this section, we will **simulate toy behavioural data**.
For that, we start by making some arbitrary metadata.
Here, we have 40 animals, condition "A" vs "B", and sex, male ("M") or female ("F").

```{r}
library(ggetho)

metadata <- data.table(id=sprintf("toy_experiment|%02d" , 1:40), region_id=1:40,
                   condition=c("A","B"),
                   sex=c("M","M", "F", "F"))
head(metadata)

dt <- toy_activity_data(metadata, seed=107)
```
Now, we have a [behavr](behavr.html) object, `dt`:

```{r}
summary(dt)
```


This data is stored in a [behavr table](behavr.html).
It has a column `moving` that that tells us whether an the animal `id` is moving at a time `t`.

## The `ggetho()` function{-}

`ggetho()` is the core function.
It expresses the **relationship between variables**.
In this respect, it works very much like `ggplot()`, but it also pre-processes the data.

It is important to understand the **difference between `ggplot()` and `ggetho()`**.
`ggplot()` is a works with data frames (or data tables), and does not preprocess the data.
`ggetho()` is only a layer on top of `ggplot()`. 
It works **exclusively with `behavr` tables** and does preprocess data before calling `ggplot()`.
`ggetho()` does return `ggplot` a object, therefore, layers available in `ggplot2` can be used natively on top of `ggetho`. 

Let's work with an example. Say, we would like:

* The proportion of time spent **moving, on the y axis**
* Versus **time, on the x axis**

We could write:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving))
pl
```

This generates an **empty plot** this is normal because we have, so far, **no layer**.
We will see some layers very soon!

The role of `ggetho` is to express a relationship between variables and to **compute a summary**, over a certain time window, of a variable of interest **for each individual**.

Importantly, **you decide which variable you want to plot**.
For instance, you could be interested in things like the number (sum) of beam crosses or the average position.

## Tile plots{-}

### Per individual{-}

One of the most interesting layer is `stat_tile_etho`.
It shows the **variable of interest in the (colour) z axis**.
The y axis is discrete (generally the id), taht is **one row per individual**.
The x axis is time (by default, summerised, by `ggetho`, over 30 minutes).
So, if we want to show the proportion of time spent moving over time for each individual (id):


```{r}
pl <- ggetho(dt, aes(x=t, y=id, z=moving)) + stat_tile_etho()
pl
```

By defaut, each pixel is the **mean** (`summary_FUN = mean`, in `ggetho`), over 30 min (`summary_time_window = mins(30)`, in `ggetho()`).
Also, note that the default is `x=t` and `y=id`, so we could just obtain exactly the same with
`ggetho(dt, aes(z=moving)) + stat_tile_etho()`.


### Sorted individual{-}

Sometimes, we want to sort individuals based on a metavariable (discrete or continuous).
For instance let us compute the overall average fraction of time spent moving,
**add it to the metadata**, to then sort individuals from low to high movers:

First, we add a new metavariable (`mean_moving`):
```{r}
# the average time spent moving per 1000 (rounded)
mean_mov_dt <- dt[, .(mean_moving = round(mean(moving) * 1000)), by=id]
# join curent meta and the summary table
new_meta <- dt[mean_mov_dt, meta=T]
# set new metadata
setmeta(dt, new_meta)
head(dt[meta=T])
```
Proportion of time moving (`mean(moving)`) will be a number between zero and one, with sometimes many decimals,
whichs makes it hard to read.
A more intuitive way to express it is as a rounded per mille (‰).
I prefer it to per cent as we have more more resolution (i.e. less ties)
For instance, `0.0113333` would be expressed as `11`. 

Now, we can express a new relationship where we show the *interaction* between our custom variable and id, on the y axis:

```{r}
pl <- ggetho(dt, aes(x=t, y=interaction(id, mean_moving, sep = " : "), z=moving)) +
              stat_tile_etho()
pl
```

Since we use `" : "` as a separator, we have, on the y axis, names as `<id> : <mean_sleep>`.
You can extend this concept to sort also by *males vs females*:

```{r}
pl <- ggetho(dt, aes(x=t, y=interaction(id, mean_moving, sex, sep = " : "), z=moving)) +
              stat_tile_etho()
pl
```

### Group averages{-}

Sometimes, we also want to aggregate individuals per group.
For instance, males **average** vs females **average**.
This can be done by changing the `y` axis. Previously, we used `id`, which made one row per individual.
Instead, if we use a grouping variable like `sex`, we will plot one row per value of `sex` (i.e. two rows, one for males, one for females). In other words, we replace `id` by `sex` on the y axis:
```{r}
pl <- ggetho(dt, aes(x=t, y=sex, z=moving)) + stat_tile_etho()
pl
```
In this context, **every row is not an individual any more, but a population**.
The `method` argument of `stat_tile_etho()` allows you to use other aggregates (median, max, min, ...).

### Bar tiles {-}
The bar_tile is a variant of our tile plot.
Instead of colour intensity, **it shows our z variable by the height of the tiles**.
You can use it just by replacing `stat_tile_etho` by `stat_bar_tile_etho`:

```{r}
pl <- ggetho(dt, aes(x=t, z=moving)) + stat_bar_tile_etho()
pl
```


## Population plots{-}
### One population{-}
The problem with representing a variable on a colour axis is that it is not perceptually comparable, and we cannot make error bars.
When the number of groups is not too high, it makes sense to  show **the variable of interest on the y axis**, and then draw lines between consecutive points.
For this, we can use the `stat_pop_etho()` function:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho()
pl
```

By defaut, the local average and error bars are computed from the mean an standard errors (`method = mean_se`).
You can compute other types of error bars e.g. bootstrap (`method = mean_cl_boot`).

### Several populations{-}

Often, we want to compare population with respect to a variable.
There are different way to split populations. We can, for instance, **use a different colour line for different groups**:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving, colour=sex)) + stat_pop_etho()
pl
```


Another way, is to use `ggplot`'s faceting system:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() +
            facet_grid(sex ~ .)
pl
```

Of course, you can combine both when you have more than one relevant metavariable:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving, colour = sex)) +
              stat_pop_etho() +
              facet_grid( condition ~ .)
pl
```


## Wrapping data{-}
When behaviours are periodic, we sometimes want to average our variable at the same time over consecutive days.
In ggetho, we call that time *wrapping*.
It can be done simply with the `time_wrap` argument.
It will work the same for population or tile plots:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving), time_wrap = hours(24)) + stat_pop_etho()
pl
```

Note that you do not have to wrap over specifically 24h, you could work different periods.

If you are interested in events that happen between the end and the start of the wrapping period (e.g. at ZT24).
You may want to wrap time with an **"offset"**. That is a phase shift. For instance, if we want to have ZT06 in the middle of our graph, we use an offset of +6h:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving), 
             time_wrap = hours(24),
             time_offset = hours(6)) + stat_pop_etho()
pl
```

As you can see, it gives have a nice visualisation of the "activity peaks".

## Double-plotted actograms {-}

When analysing periodic behaviour, it makes sense to use a so called double-plotted actogram.
This is very useful **to understand periodicity of behaviours**.

This means data is plotted twice, in a staggered manner:
```
row1 [day 1, day2]
row1 [day 2, day3]
row1 [day 3, day4]
```

To do that, we can set the `multiplot` argument of `ggetho` to `2` (`3` would do a "tripple-plotted" actogram).
This averages the whole population:

```{r}
pl <- ggetho(dt, aes(x=t, z=moving), multiplot = 2) + stat_bar_tile_etho()
pl
```


In practice, we genrally want to do that for **one specific individual** (see next section to do that automatically):

```{r}
pl <- ggetho(dt[id=="toy_experiment|01"],
             aes(x=t, z=moving), multiplot = 2) + stat_bar_tile_etho()
pl
```


One thing you can do is change the length of the period. 
For instance **25h instead of 24h**:

```{r}
pl <- ggetho(dt[id=="toy_experiment|01"], aes(x=t, z=moving), 
             multiplot = 2,
             multiplot_period = hours(25) # this is the important part
             ) + 
  stat_bar_tile_etho()
pl
```


Keep in mind that you can use the **tile representation if you prefer** it:

```{r}
pl <- ggetho(dt[id=="toy_experiment|01"], aes(x=t, z=moving), 
             multiplot = 2
             ) + 
  stat_tile_etho() # tile here
pl
```

## Faceting by ID {-}

When multiplotting, it is difficult to represent individuals (since both y and x axis are used).

### Default {-}
The best way to systematically represent all of them is to use facetting, which is a ggplot feature.
Since id represent unique individuals, **each facet (sub-rectangle) is one individual**:

```{r, fig.width=10, fig.height=6}
pl <- ggetho(dt, aes(x=t, z=moving), 
             multiplot = 2
             ) + 
  stat_bar_tile_etho() +
  facet_wrap( ~ id)
pl
```


### Custom labeller {-}

Sometimes, the `id` variable will be very long, you can use the `id_labeller` to make things clearer:

```{r, fig.width=10, fig.height=6}
pl <- ggetho(dt, aes(x=t, z=moving), 
             multiplot = 2
             ) + 
  stat_bar_tile_etho() +
  facet_wrap( ~ id, labeller = "id_labeller")
pl
```
 
### Numerical labelling {-}

Even with the trick above, ids may become unreadable when plotting many individuals.
What we can can do in this case is to use numbers instead.
Firt, we create a new metavariable named, for instance, `uid`. 
It will be one **unique number** per individual:

```{r}
dt[, uid := 1:.N, meta=T]
print(dt[meta=T])
```

Then, we can use `uid` instead of `id`:

```{r, fig.width=10, fig.height=6}
pl <- ggetho(dt, aes(x=t, z=moving), 
             multiplot = 2
             ) + 
  stat_bar_tile_etho() +
  facet_wrap( ~ uid)
pl
```

Since we kept both `id` and `uid` in the metadata, we can map them again each other.

The downside of using numbers, is that they are **ambiguous**. 
Say, you decide to start with more data, or to remove some, then the numbers (`uid`) will not match their previous `id`.
Conversely, if you try to analyse different datasets independently, and merge results afterwards, you will end up with duplicates in `uid`. Therefore, only use this trick for readability and visualisation.

If you want to understand facets a bit more, have a look at [this tutorial](http://www.cookbook-r.com/Graphs/Facets_(ggplot2)/).



## LD annotations{-}

### Basics{-}
In circadian experiments, we often like to add annotations (black and white boxes) to show Dark and Light phases. We have another layer for that:


```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() + stat_ld_annotations()
pl
```

### Changing LD colours{-}

Sometimes you want different colours to explains, for instance, that days are "subjective"(grey).

```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() +
              stat_ld_annotations(ld_colours = c("grey", "black"))
pl
```


### LD in the background{-}

To put the annotation in the background, we can invert the order of the layers, set the heigh of the annotation to 1 (100%) and add some transparency (`alpha = 0.3`). We also remove the outline of the boxes:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) +
            stat_ld_annotations(height=1, alpha=0.3, outline = NA) +
            stat_pop_etho()
pl
```

### Phase and period{-}

Sometimes you want to show annotations with different phases and periods.
For instance, here, we shift the LD annotations 1h forward:
```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) +
            stat_ld_annotations(phase = hours(1)) +
            stat_pop_etho()
pl
```

One can also plot over a period different from 24h, say 20h days:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) +
            stat_ld_annotations(period = hours(20)) +
            stat_pop_etho()
pl
```

### Regime change{-}

When, you want to indicate a change in regime, say from LD to DD.
A simple way is to use multiple layers with explicit start and end points:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) +
            # the default annotation layer
            stat_ld_annotations() +
            # on top of it, a second layer that
            # starts at day 2 thoughout day 5,
            # and where L colour is grey
            stat_ld_annotations(x_limits = days(c(2,5)),
                                ld_colours = c("grey", "black" )) +
            stat_pop_etho()
pl
```

## Coordinate and scales{-}

### Plot limits{-}
As `ggetho` creates regular ggplot objects, which we can extend. For instance, we can change the scales.
For instance, put the y scale as a percentage between 0 and 100:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() +
        stat_ld_annotations()
pl <- pl + scale_y_continuous(limits = c(0,1),
                              labels = scales::percent)
pl
```


We can also use the same principle to zoom in a finished plot. E.g. between day one and day two:
```{r}
pl + coord_cartesian(xlim=c(days(1), days(2)))
```


### Time scale units{-}

By default, `ggetho` decides the unit of the time axis according to the range of the data.
Sometime you want to override this behaviour to force time to be in a specific unit (here hours).
Using the plot above, we can add a scale:

```{r}
pl + ggetho::scale_x_hours()
```

`R` actually warns you since you are replacing the scale.
Which is fine (as it is precisely what we wanted)!

### Coordinate systems{-}

Sometimes, it makes sense to use **polar coordinates** to show data around the clock:

```{r}
pl <- ggetho(dt, aes(x=t, y=moving, colour=sex), time_wrap = days(1)) +
          stat_ld_annotations(height=.5,
                              alpha=.2,
                              x_limits = c(0, days(1)),
                              outline = NA) +
          stat_pop_etho(geom = "polygon", fill=NA)

pl + coord_polar()
```


## Periodograms {-}

To draw periodogram, we can use our special fucntion `ggperio`.

The library `zeitgebr` generates periodogram as `behavr` tables. with columns for power, period ...
```{r}
library(zeitgebr)
dt[, t := ifelse(xmv(condition) == "A", t, t * 1.01)]
per_dt <- periodogram(moving, dt, FUN = chi_sq_periodogram, resample_rate = 1/mins(5))
per_dt
```

An average periodogram:
```{r}
ggperio(per_dt, aes(period, power, colour=condition)) + 
        stat_pop_etho()
```

Faceted by uid:
```{r}
ggperio(per_dt, aes(period, power, colour=condition)) + 
        geom_line() + facet_wrap( ~ uid)
```


Showing peaks:

```{r}
per_dt <-find_peaks(per_dt)
ggperio(per_dt, aes(period, power, colour=condition)) + 
        geom_line() +
        geom_peak(colour="blue") +
        facet_wrap( ~ uid) 
```

## Take home message{-}
 
`ggetho` provides you with a new set of stats, layers and scales to represent behaviours.
In particular, `ggetho` and `ggperio` can be used to preprocess `behavr` tables in order to use a regular `ggplot2`
workflow.

## Next steps {-}

* [Sleep analysis with `sleepr`](sleepr.html)
* [Circadian analysis with `zeitgebr`](zeitgebr.html)



<!-- library(ggetho) -->
<!-- metadata <- data.table(id=sprintf("toy_experiment|%02d" , 1:40), region_id=1:40, -->
<!--                    condition=c("A","B"), -->
<!--                    sex=c("M","M", "F", "F")) -->
<!-- head(metadata) -->

<!-- dt <- toy_activity_data(metadata, seed=107) -->

<!-- pl <- ggetho(dt, aes(x=t, y=moving)) + -->
<!--             stat_ld_annotations(phase = hours(-1)) + -->
<!--             stat_pop_etho() -->
<!-- pl -->

<!--chapter:end:07-ggetho.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# Sleep analysis {#sleepr -}

<!-- **TODO the perfect one liner** -->

<!-- --------------------------- -->

<!-- ![TODO add some figure]("rethomics_files/figure-html/achitecture-1.png") -->

## Aims {-}
In this practical chapter, we will use a real experiment to learn how to:

* Annotate a [behavr table](behavr.html) with **sleep state**
* Use [ggetho](ggetho.html) to display individual and population sleep amounts
* Compute **average sleep** within a time window
* Perform standard statistics on average sleep
* Analyse sleep **architecture**, sleep **latency**,...

## Prerequisites {-}
* You have read about [behavr tables](behavr.html)
* You are familiar with  [ggetho](ggetho.html), our vidualisation tool
* You have already read the [damr tutorial](damr.html)
* Ensure you have [installed](intro.html#installing-rethomics-packages)
`behavr`, `damr` and `ggetho` packages:


## Background{-}

This tutorial focused on sleep in *Drosophila*.
Traditionally, activity is first scored (e.g. though beam crosses/video tracking).
Then any bout of inactivity longer than five minutes counts as sleep.
You can easily adapt this tutorial to scoring other models/behaviours as long as you can define **two discrete states** (e.g. sleep vs asleep, moving vs immobile, left vs right, ...).

In the [DAM tutorial](damr.html), we have learnt how to load data from a real DAM expriment.
Since we already described it in length, it makes sense to use this experiment as an example for our sleep analysis.
**I will assume that you have already read and understood the [DAM tutorial](damr.html)**.
The last thing we did then was loading data and scoring sleep:

```{r, eval=FALSE}
library(sleepr)
dt <- load_dam(metadata, FUN = sleepr::sleep_dam_annotation)
dt
```


## Getting the data {-}

Instead of going through the whole `damr` tutorial again, I thought I would put the resulting data table online.
Importanlty, for simplicity, **I have just kept replicate 1**.
We just need to download it and load it:


```{r}
library(sleepr)
library(ggetho)

URL <- "https://github.com/rethomics/rethomics.github.io/raw/source/material/sleep_dam.RData"
load(url(URL))
summary(dt)
```

## Data curation {-}
First of all, lets visualise all our sleep data.
It is important to **pay critical attention to this graph** in order to assess if anything has gone wrong:

```{r, fig.width = 9, fig.height=12}
ggetho(dt, aes(z=asleep)) +
      stat_ld_annotations(height = 1)+
      stat_tile_etho() 
      
```

### Dead animals {-}

Some animals may have died during the experiment, and could be wrongly scored as asleep for very long durations.
`sleepr` has an utility function to remove data from dead animals:

```{r}
# we give our curated data another name so we can see the difference
dt_curated <- curate_dead_animals(dt)
summary(dt_curated)
```
As you can see, we now have `r nrow(dt_curated[meta=T])` individuals vs `r nrow(dt[meta=T])` in the original data.
To see which animals have been removed, we could run something like:

```{r}
setdiff(dt[, id, meta=T],
        dt_curated[, id, meta=T])
```
Indeed, from the tile plot nothing seem to have happened in this channel.
Now let us look at the data after curation:

```{r, fig.width = 9, fig.height=12}
ggetho(dt_curated, aes(z=asleep)) +
      stat_ld_annotations(ypos = "top")+
      stat_tile_etho() 
```

### Animals that died too early {-}

In addition, we could want to, for instance, **remove animals that did not live say longer than 2 days**.
Of course, you need to have a good reason to exclude some animals, and that depends on your specific experiment (this is just showing you how to do it).
To remove animals that did not live longer that 2 days, we use the power of `behavr` tables:

```{r}
# we make a summary table of all lifespan for each animals
lifespan_dt <- dt_curated[, .(lifespan = max(t)), by=id]
# we filter this table for lifespan>2 and we keep the id
valid_ids <- lifespan_dt[lifespan > days(2), id]
# we apply this filter
dt_curated <- dt_curated[id %in% valid_ids]
summary(dt_curated)
```

### Trimming {-}
Generally, we want to remove point according the experimental time.
For instance, lets say we would like to keep only the first 60 hours of data (i.e. 2.5 days)


```{r}
dt_curated <- dt_curated[t %between% c(days(0), days(2.5))]
summary(dt_curated)
```

Which means we are only considering data **between** 0 and 2.5 days. 

The same principle can be used to remove the begining of an experiment. Fon instance when animals are acclimatising to their new environment.

## Population plots{-}

Now that we have curated our data, we can start looking at the biology.
First, we make a global population plot:

```{r}
ggetho(dt_curated, aes(y=asleep, colour=sex)) +
      stat_pop_etho() +
      stat_ld_annotations() +
      facet_grid(genotype ~ .)
```

The y axis shows the proportion of time sent sleeping, averaged for each animal within a 30min (default) time window.

Then, we can wrap (average) that over one day. We also polish the y axis label:

```{r}
ggetho(dt_curated, aes(y=asleep, colour=sex), time_wrap = hours(24)) +
      stat_pop_etho() +
      stat_ld_annotations() +
      facet_grid(genotype ~ .) +
      scale_y_continuous(name= "Fraction of time sleeping",labels = scales::percent)
```

That gives us a good understanding of what happens at the population level.

## Summarise data per animal{-}

Most likely, we want to summarise sleep amount so that we have **one number per animal**.
For instance, we can compute the overall average proportion of time spent sleeping:

```{r}
summary_dt <- 
  rejoin(dt_curated[,
           .(
             # this is where the computation happens
             sleep_fraction = mean(asleep)
             ),
           by=id])
summary_dt
```
With `rejoin`, we have put our summary and metadata together, which is suitable for standars graphics/statictics.
For instance, if we are interested in the effect of sleep and genotype on sleep amount, we can make a faceted boxplot, and also add individual points to show all data.

```{r}
ggplot(summary_dt, aes(x=sex, y=sleep_fraction, fill=sex)) + 
  geom_boxplot(outlier.colour = NA) +
  geom_jitter(alpha=.5) +
  facet_grid( genotype ~ .) +
  scale_y_continuous(name= "Fraction of time sleeping",labels = scales::percent)
```

## Day sleep☼ -- Night sleep☾{-}

Often, we want to compare amount of sleep during the day vs night as they are different processes.
 
### Adding some phase information {-}
The simplest way to do that is to start by adding some phase information to our data.

* **L phase** (light) should be any point **between ZT0 and ZT12** -- [0,12), [24,36), ...
* **D phase** (dark) should be any point **between ZT12 and ZT24** -- [12,24), [36,48), ...

Numerically, this can be done very simply using a [modulo operation](https://en.wikipedia.org/wiki/Modulo_operation) on time. In `R`, modulo is `%%`.
The following line creates a new variable in dt. This variable is:
  
* `"L"`  when the remainder of the division of (the corresponding) `t` by 24h is lower than 12h
* `"D"`  otherwise

```{r}
dt_curated[, phase := ifelse(t %% hours(24) < hours(12), "L", "D")]
```

Since we have this column, we can make an improved summary (pay special attention to the last columns):

```{r}
 
summary_dt <- 
  rejoin(dt_curated[,
           .(
             # this is where the computation happens
             sleep_fraction_all = mean(asleep),
             sleep_fraction_l = mean(asleep[phase == "L"]),
             sleep_fraction_d = mean(asleep[phase == "D"])
             ),
           ,by=id])
summary_dt
```
Now, we have three new variables: `sleep_fraction_all`, `sleep_fraction_l` and `sleep_fraction_d`.
We can just replace the y axis with our variable of interest (e.g. sleep in D phase):

```{r}
ggplot(summary_dt, aes(x=sex, y=sleep_fraction_d, fill=sex)) + 
  geom_boxplot(outlier.colour = NA) +
  geom_jitter(alpha=.5) +
  facet_grid(genotype ~ .) +
  scale_y_continuous(name= "Fraction of time sleeping",labels = scales::percent)
```

If we wanted a plot will all three values, we could ["melt"](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reshape.html) our data,
picking all columns starting with `"sleep_fraction_"` as "measurment variables":

```{r}
summary_dt_melted <- melt(summary_dt, measure.vars = patterns("sleep_fraction_"),
                          variable.name = "phase", value.name = "sleep_fraction")
```

Now, instead of three columns for the three variable, we have two columns, one for the actual value and one to describe the phase (all vs L vs D). 
This makes it convenient to use with ggplot:

```{r}
ggplot(summary_dt_melted, aes(x=phase, y=sleep_fraction, fill=sex)) + 
  geom_boxplot(outlier.colour = NA) +
  geom_jitter(alpha=.5) +
  facet_grid(genotype ~ .) +
  scale_y_continuous(name= "Fraction of time sleeping",labels = scales::percent)
```

## Statistics {-}

Often, you want to go further than representing the data, and compute statistics.
`R` was designed primarilly as statistical progamming language.
As a result, a tremendous variety of simple and elaborate statics are implemented.
This section will not go in the details of what you can do in terms of stats, many authors have already published fantastic ressources on this subject.
Instead, we present a very simple examples of what can be done.
At this stage, what you do depends very much on your question, your knowledge of statistics and how much effort you
want to invest.

### Pairwise Wilcoxon tests {-}

Say we wanted to compute, for **females only**, all pairwise tests between all genotype groups (A vs B, B vs C and C vs A). This could be formulated as:

```{r}
pairwise.wilcox.test(summary_dt[sex=="F", sleep_fraction_all], 
                     summary_dt[sex=="F", genotype])
```
We get a matrix showing us all p-values.
You could do that also within males, as long as we replace `sex == "F"` by `sex == "M"`

### Two way anova {-}

If we are interested in the effect of **sex AND genotype**, as well as **their interaction**,
we can model our response variable with a formula: `sleep_fraction_all ~ sex * genotype`:

```{r}
model <- aov(sleep_fraction_all ~ sex * genotype, summary_dt)
summary(model)
```

This shows a strong affect of sex, genotype and their interaction on sleep amount.
There are several way to follow up.
For instance see this [short tutorial](https://www.r-bloggers.com/two-way-analysis-of-variance-anova/).

## Sleep architecture {-}

Proportion alone is not always a sufficent measure to fully descibe the dynamics of sleep.
One way to go further is to study seep as a series of bouts.

### Bout analysis{-}
The function `bout_analysis()`, in `sleepr` is designed for that.
We would use it like that:

```{r}
bout_dt <- bout_analysis(asleep, dt_curated)
```
The result is a new behavr table, with a few differences compared to the ones we used before:

* Each row in the data describes a bout
* The bout can take the values `asleep=TRUE` or `asleep=FALSE` (sleep bout or wake bout, respectively)
* `t` is the onset of the bout (in seconds)
* `duration` is length of the bout (in seconds)

Note that you can use this function to study bouts of other discrete behaviours.
For now, we are only interested in **sleep bout**, so we filter for `asleep == TRUE`.
We also remove the, now redundant, `asleep` column:

```{r}
bout_dt <- bout_dt[asleep == TRUE, -"asleep"]
```

### Bout length vs time of the day {-}

We can use `ggetho` to show how the average bout length depend of the time of the onset of the bout.

```{r}
ggetho(bout_dt, aes(y=duration / 60, colour="sex"), time_wrap = hours(24)) + 
      stat_pop_etho() + 
      facet_grid(genotype ~ .) +
      scale_y_continuous(name= "Bout length (min)")

```

Note that this is a bit noisy as we only have a few animals per conbination of treatment.


### Architecture description {-}

One can count the total number of bouts and average bout duration for each individual like so:

```{r}
bout_dt[,
        .(n_bouts = .N,
          mean_bout_length = mean(duration)),
        by=id]
```
You could apply the approach presented before to compute statistics according the the phase (night vs day bouts).

### Latency to sleep {-}

The latency describe how long it takes for an animal to initiates its **first sleep bout**.
Some researchers are also interested in the latency to the **longest bout**.
In this example, lets say we focus on the second day (and not the night -- 24 to 36 hours).

```{r}
bout_dt_second_day <- bout_dt[t %between%  c(days(1), days(1) + hours(12))]
# We express t relatively to the first day
bout_dt_second_day[, t:= t - days(1)]
bout_summary <- bout_dt_second_day[,.(
                      latency = t[1], # the first bout is at t[1] 
                      first_bout_length = duration[1],
                      latency_to_longest_bout = t[which.max(duration)],
                      length_longest_bout = max(duration),
                      n_bouts = .N,
                      mean_bout_length = mean(duration)
                      ),
                      by=id]
bout_summary
```

For good measures, I also added number of bout and average bout length as we have seen before.
You can of course use these result to plot things like the relationship between bout length and bout number:

```{r achitecture}
ggplot(rejoin(bout_summary), aes(n_bouts, mean_bout_length, colour=sex)) +
    geom_point() +
    facet_grid(genotype ~ .) + 
    scale_x_continuous(name="Number of bouts") +
    scale_y_continuous(name="Average bout duration (s)")
```

Always **be critical** about what you do.
For instance, what whould be the latency to sleep of an animal that, in the period of observation, does not sleep?

## Merging all statistics {-}

Earlier, we made a `summary_dt` in which we computed some statitic ssuch as sleep fraction in L and D phase.
In addition, we have now a `bout_summary` where we have other variables.
These data have both one row per animal.
Ideally, we could **"merge" them into a single table** that has all the individual statistics.
This way we can study the relationship say between sleep amount and latency.
In order to do that, we perform a so called "join":

```{r}
overall_summary <- summary_dt[bout_summary]
overall_summary
```

```{r}
ggplot(overall_summary, aes(latency / 60, sleep_fraction_l, colour=sex)) +
    geom_point() +
    geom_smooth(method="lm", alpha=.1)+
    facet_grid(genotype ~ .)
```



## Take home message{-}

Data analysis and visualisation is about **translating your biological questions to another language**.
Problems in emerging areas of science can be very rich so they should be matched with the equally rich grammar that only a programming language can provide.
This tutorial was very simple and does not pretend to provied a canonical sleep analysis.
Instead, see it as a set of building blocks that you can use and rearange to address your own questions.


## Next steps {-}

* [Visualise data with `ggetho`](ggetho.html)
* [Circadian analysis with `zeitgebr`](zeitgebr.html)

<!--chapter:end:08-sleepr.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# Circadian rhythm analysis {#zeitgebr -}

<!-- **TODO the perfect one liner** -->

<!-- --------------------------- -->

<!-- ![TODO add some figure]("rethomics_files/figure-html/achitecture-1.png") -->

## Aims {-}
In this practical chapter, we will use a real experiment to learn how to:

* Use `zeitgebr` to compute periodograms
* Use [ggetho](ggetho.html) to draw double plotted actograms
* Average periodograms vs conditions
* Find and compare peaks 

## Prerequisites {-}
* You have read about [behavr tables](behavr.html)
* You are familiar with  [ggetho](ggetho.html), our visualisation tool
* You have already read the [damr tutorial](damr.html)
* Ensure you have [installed](intro.html#installing-rethomics-packages)
`behavr`, `damr`, `ggetho` and `zeitgebr` packages


## Background{-}

This tutorial focuses on circadian rhythm in *Drosophila*, but can be adapted easily to investigate periodicity in different contexts.
In it, we will use a DAM dataset that is provided (and preloaded) within the `damr` package.

## Getting the data {-}

Getting the data a lot simpler than in the other tutorials as it is already on your computer:

```{r}
library(damr)
library(zeitgebr)
library(ggetho)

# We load the data
data(dams_sample) 
# We copy the data to our own variable so we can alter it
dt <- copy(dams_sample) 
```
This data set is recording of 32 animals, in DD.
Let us print the metadata to understand the experiment a little bit:

```{r}
summary(dt)
print(dt[meta=T])
```

We can confirm we have 32 individuals. 
They are described by one of three "period groups" (e.g. a genotype or treatment). 
This is encoded int `period_group` metavariable can be either a "short"", "long"" or wild-type ("wt") period.

## Quality control {-}
This data is fairely clean already, so we will not do much.
For most purposes, you can apply the same principles as [data curation for sleep analysis](sleepr.html#data-curation).

### Regime changes {-}

In general (but not here), you will have a period of `LD` **"baseline"** preceding a change to a `DD` regime.
I suggest to encode that in the following way:

1. Manually add a column `baseline_days` in your metadata that defines the **number of days of baseline**.
2. **Sustract the number of baseline days** to all time points: `dt[, t := t - days(xmv(baseline_days))]`

As a result, `t = 0` now means "ZT0 of the transition day".
This makes a lot of sense as any baseline point is at a negative time (`t < 0`), whilst `t > 0` is for `DD`.
The nice thing is that you can work with data (e.g. replicates) that have different baseline duration as now **all time points are relative to the regime change**.

### Data enrichment {-}

By defaut, DAM data only has variables `t` and `activity`. The latter being the number of beam crosses over a time bin (e.g. one minute). We could define a variable `moving` that is `TRUE` when and only when `activity > 0`, and `FALSE` otherwise:

```{r}
dt[, moving := activity > 0]
```


### Overview plots {-}

The first representation we show could be activity all animals over time in the same page.
This would help to spot ourliers.
We simply do that with our **tile plot**.
Note how we have changed the LD colours to grey and black, grey being for subjective days (remember, we are in DD).

```{r, fig.width = 9, fig.height=12}
ggetho(dt, aes(z=activity)) +
      stat_ld_annotations(ld_colours = c("grey", "black"))+
      stat_tile_etho() 
```

Note that you can substitute `activity` by other variables you have in `dt` (e.g. `moving`).


We see that two animals (region 5 and 10) seem to have died/escaped before the end of the experiment.
There is no right thing to do regarding dead animals. You could keep the data before death, or remove them altogether.
**It is eventually your responsibility to decide what to do with dead animals**. 
Here, I simply remove data after death:

```{r}
library(sleepr)
dt_curated <- curate_dead_animals(dt)
summary(dt_curated)
ggetho(dt_curated, aes(z=activity)) +
      stat_ld_annotations(ld_colours = c("grey", "black"))+
      stat_tile_etho() 

```

Our curated data is now stored in `dt_curated`.

## Double plotted actograms {-}

At the moment, the `id` is a very long string (e.g. `"2017-01-16 08:00:00|dams_sample.txt|01"`). It has the advantage to be unambiguous, but it is difficult to plot.
To help plotting, we can make a new variable that is simply **a different number for each individual**. Lets call it `uid`:

```{r}
dt_curated[, uid := 1 : .N, meta=T]
# We can map uid to id
dt_curated[, .(id, uid) ,meta=T]
```
As you see, we do keep `id` as a reference but `uid` for convenience in graphs.

To make a double plotted actogram, we use `ggetho`.
Read more about that in the [visualisation tutorial](ggetho.html#double-plotted-actograms).
Briefly, we set `multiplot` to `2` (`3` would be a triple plotted) one.
The variable of interest is on the `z` axis.
Note that instead of `moving`, you could plot raw `activity`.
Then, we use bar height to show the amount of movement (we could use `stat_tile_etho` which shows the variable of interest as colour a pixel intensity). 
Lastly, we split the graph by `uid`, so that each facet is a single animal.

```{r, fig.width = 12, fig.height=6}
ggetho(dt_curated, aes(z = moving), multiplot = 2) + 
    stat_bar_tile_etho() +
    facet_wrap( ~ uid, ncol = 8)
```

Interestingly, you can use formula in facet to show or sort with other metavariables:

```{r, fig.width = 12, fig.height=6}
ggetho(dt_curated, aes(z=moving), multiplot = 2) + 
    stat_bar_tile_etho() +
    facet_wrap( ~ period_group + uid, ncol=8, labeller = label_wrap_gen(multi_line=FALSE))
```
Now, we know which genotype match each `uid`. 
In your own work, you could generalise this concept to display more metavariables.
For instance, if you had a `sex` metavariable you could do: `facet_wrap( ~ period_group + sex + uid, ...)`.



## Periodograms {-}

### Computation {-}

An important part of circadian research is to compute the periodicity of the free running clock of multiple individuals.
Mathematically, we would like to build a preiodogram. That is, generally speaking, a representation of the density (i.e. **power**) of a signal at different **periods** (or frequencies).
In addition, a periodogram associates to each pair of power-period a **significance level**.
There are many algorithms to compute periodograms.
In `zeitgebr`, we have si far implemented:

* `ac_periodogram` -- An *autocorrelation* based method
* `ls_periodogram` -- *Lomb-Scargle* algorithm
* `chi_sq_periodogram` -- A *$\chi{}^2$* based one

See `?periodogram_methods` for references.

In order to compute periodograms, we use the `periodogram()` function.
We need to define which variable we want to study (e.g. `moving` or `activity`).
Then, we provide our data.
The methods described above can be passed as an argument.

For instance, if we want to analyse, with the $\chi{}^2$ method, activity:

```{r}
per_xsq_dt <- periodogram(activity, 
                        dt_curated,
                        FUN = chi_sq_periodogram)
per_xsq_dt
```
The result is another `behavr` table, with the same metadata. 
The data however, is now a list of power vs period (and significance).

Have a look at the other options (see `?periodogram`).

### Peaks finding {-}

Often, we want to know which are the peak periods in a periodogram.
This can be achieved thanks to the `find_peaks` function.
By default, it find a maximum of three peaks, which are sorted by their power (relative to the significance thershold).
Peaks that are not signifant are not accounted for (see the `alpha` argument).

```{r}
per_xsq_dt <- find_peaks(per_xsq_dt)
per_xsq_dt
```

This function annotates our data by adding a column named `"peak"`.
Whenever the row corresponds to a peak, it puts a number and `NA` otherwise.
The number is the rank of the peak (`1` being the first/tallest one).

### Visualisation{-}

In `ggetho`, the function `ggperio()` is designed specifically for displaying periodograms.
One could plot all the periodograms like so:

```{r}
ggperio(per_xsq_dt) + geom_line(aes(group = id, colour=period_group))
```

But it is very hard to read, so we will **facet per `uid`**.
In addition, we can use a special geometry (`geom_peak`) to show the values of the peak.
We draw a signifiance line as well, just using the `signif_threshold` variable:

```{r, fig.width = 12, fig.height=6}
ggperio(per_xsq_dt) + 
  geom_line(aes(group = id, colour = period_group)) +
  geom_peak(col = "black") +
  geom_line(aes(y = signif_threshold)) +
  facet_wrap(~ uid, ncol = 8)
```


Instead of drawing only the first peak, you could draw, for instance,  the first and second (`geom_peak(peak_rank = 1:2)`) or, only the second (`geom_peak(peak_rank = 2)`).

An interesting thing to do is a population average periodogram.
In this graph, the solid lines are the average power per group, whilst the shaded areas are ± standard error:

```{r}
ggperio(per_xsq_dt, aes(
                  y = power - signif_threshold,
                  colour=period_group)) + 
                  stat_pop_etho()
```

### Exctract the peak values {-}

At some point, you would like to **summarise** each animal by, say, it first peak.
Then, you can look at whether there are significant difference in peak periodicity vs genotype.
Doing that is quite straigtforward.
First, we **select only rows where peak is exactly 1**, then [rejoin](https://rethomics.github.io/behavr.html#operating-on-behavr-tables) our table to its metadata:

```{r}
summary_dt <- rejoin(per_xsq_dt[peak==1])
summary_dt
```


`summary_dt` can be used as a standard `R` dataframe for further analysis.
For instance, with `ggplot`, I make a **boxplot showing the distribution of periods**, in h,  for each groups.
I also add **a point for each animal** (so we see outliers). 
Then, I make the **size of the points proportional to the relative power of the peak discovered**, so we get an idea of how much to "trust" this point.

```{r}
ggplot(summary_dt, aes(period_group, period, fill= period_group)) + 
        geom_boxplot(outlier.colour = NA) +
        geom_jitter(aes(size=power -  signif_threshold), alpha=.5) +
        scale_y_hours(name = "Period (h)") 
```

Another direction could be to perform pairwise wilcoxon tests between groups:

```{r}
pairwise.wilcox.test(summary_dt$period, summary_dt$period_group )
```

This tells us that their is a statistically significant difference between each pair of group.

## Next steps {-}

* [Visualise data with `ggetho`](ggetho.html)
* [Sleep analysis `sleepr`](sleepr.html)


<!--chapter:end:09-zeitgebr.Rmd-->

```{r include=FALSE, cache=FALSE}
options("datatable.print.nrows" = 30)
```
# Issues and community {#community -}

## Citation{-}

`retomics` is an academic software. As such, it is -- and will always be -- completely free and open source. 
**If you use rethomics as part of your research, please cite [our reference publication](https://doi.org/10.1101/305664).**

## Having troubles{-}

If you are having issues or you want help with something, the best thing you can do is **fill an "issue" on the github repository** of the relevant package.
For instance, if you are struggling to load DAMS data, you should go to the [the damr package](https://github.com/rethomics/damr/issues).
This way, you can see if other users have had the same issue, and if we are already working on it!

## Contributing {-}

We welcome external contributions and hope rethomics develops as a community.
There are several ways you can contribute:

* By requesting features and reporting bugs through the github issue system
* By sending pull requests to preexisting packages
* By volunteering to develop a new package (for instance to import a new type of data)


<!--chapter:end:99-contact.Rmd-->

